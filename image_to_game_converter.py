"""
Image-to-3D Converter & AI Vision System
Converts user drawings and images into 3D assets, code, and game environments
"""

import asyncio
import aiohttp
import base64
import json
import os
import time
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from PIL import Image
import io

class AIVisionSystem:
    """
    AI-powered vision system that understands drawings and images
    Converts them into actionable game assets
    """
    
    def __init__(self, openai_key: str):
        self.openai_key = openai_key
        self.session = None
        self.supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp']
        
    async def setup_session(self):
        """Initialize aiohttp session"""
        if not self.session:
            self.session = aiohttp.ClientSession()
    
    async def close_session(self):
        """Close aiohttp session"""
        if self.session:
            await self.session.close()
    
    async def analyze_image(
        self,
        image_path: str,
        user_intent: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze uploaded image using GPT-4 Vision
        Understands what the user wants to create
        """
        await self.setup_session()
        
        # Read and encode image
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        # Determine image type
        file_ext = Path(image_path).suffix.lower()
        mime_type = f"image/{file_ext[1:]}" if file_ext != '.jpg' else "image/jpeg"
        
        # Build analysis prompt
        analysis_prompt = self._build_analysis_prompt(user_intent)
        
        try:
            async with self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.openai_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4-vision-preview",
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": analysis_prompt
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{mime_type};base64,{image_data}",
                                        "detail": "high"
                                    }
                                }
                            ]
                        }
                    ],
                    "max_tokens": 1500,
                    "temperature": 0.4
                }
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    analysis_text = result["choices"][0]["message"]["content"]
                    
                    # Parse the analysis
                    parsed = self._parse_analysis(analysis_text)
                    
                    return {
                        "success": True,
                        "raw_analysis": analysis_text,
                        "parsed": parsed,
                        "image_path": image_path
                    }
                else:
                    return {
                        "success": False,
                        "error": f"API returned status {response.status}"
                    }
                    
        except Exception as e:
            return {
                "success": False,
                "error": f"Image analysis failed: {str(e)}"
            }
    
    def _build_analysis_prompt(self, user_intent: Optional[str]) -> str:
        """Build comprehensive analysis prompt"""
        
        base_prompt = """Analyze this image and determine what game asset or environment the user wants to create.

Provide analysis in this JSON format:
{
    "asset_type": "character|building|weapon|vehicle|prop|landscape|environment|ui_element|level_design",
    "primary_objects": ["list of main objects in image"],
    "style": "realistic|cartoon|anime|pixel_art|low_poly|stylized",
    "colors": ["dominant colors"],
    "suggested_name": "asset name",
    "complexity": "simple|medium|complex",
    "dimensions": "estimated size/scale",
    "key_features": ["notable features"],
    "recommended_approach": "3D model|2D sprite|procedural|code-based",
    "unreal_components": ["UE components needed"],
    "materials_needed": ["material types"],
    "animations_needed": ["suggested animations"],
    "gameplay_elements": ["gameplay features to implement"],
    "estimated_poly_count": "low|medium|high",
    "suitable_for": ["game genres this fits"]
}

CRITICAL: If this is a sketch or concept drawing, focus on the INTENT and DESIGN, not artistic quality.
Extract the core idea of what should be created."""

        if user_intent:
            base_prompt += f"\n\nUSER'S INTENT: {user_intent}\n\nConsider this intent when analyzing the image."
        
        return base_prompt
    
    def _parse_analysis(self, analysis_text: str) -> Dict[str, Any]:
        """Parse AI analysis into structured data"""
        
        try:
            # Try to extract JSON from the response
            start = analysis_text.find('{')
            end = analysis_text.rfind('}') + 1
            
            if start != -1 and end > start:
                json_str = analysis_text[start:end]
                return json.loads(json_str)
            else:
                # Fallback parsing
                return {
                    "asset_type": "unknown",
                    "primary_objects": [],
                    "style": "realistic",
                    "suggested_name": "UserAsset",
                    "complexity": "medium",
                    "raw_text": analysis_text
                }
        except json.JSONDecodeError:
            return {
                "asset_type": "unknown",
                "raw_text": analysis_text
            }
    
    async def generate_3d_from_image(
        self,
        image_path: str,
        analysis: Dict[str, Any],
        technique: str = "auto"
    ) -> Dict[str, Any]:
        """
        Generate 3D asset from image using various techniques
        """
        
        if technique == "auto":
            technique = analysis.get("recommended_approach", "3D model")
        
        if technique == "3D model":
            return await self._generate_3d_model(image_path, analysis)
        elif technique == "2D sprite":
            return await self._generate_2d_sprite(image_path, analysis)
        elif technique == "procedural":
            return await self._generate_procedural(image_path, analysis)
        else:
            return await self._generate_code_based(image_path, analysis)
    
    async def _generate_3d_model(
        self,
        image_path: str,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate 3D model from image
        Uses AI to create model specifications
        """
        
        # Generate detailed 3D specifications
        specs = await self._create_3d_specifications(analysis)
        
        # In production, this would call:
        # - Point-E (OpenAI's text-to-3D)
        # - Stable Diffusion 3D
        # - Meshy.ai API
        # - Or custom 3D generation pipeline
        
        # For now, create placeholder with specifications
        asset_name = analysis.get("suggested_name", "Asset3D")
        
        # Create asset file (placeholder)
        output_path = f"assets/generated_3d/{asset_name}_{int(time.time())}.fbx"
        os.makedirs("assets/generated_3d", exist_ok=True)
        
        # Generate Unreal-compatible metadata
        asset_data = {
            "asset_name": asset_name,
            "asset_type": "StaticMesh",
            "source_image": image_path,
            "specifications": specs,
            "file_path": output_path,
            "created_at": time.time(),
            "unreal_import_settings": {
                "import_materials": True,
                "import_textures": True,
                "generate_lightmap_uvs": True,
                "collision_complexity": "UseSimpleAsComplex"
            }
        }
        
        # Save metadata
        with open(output_path.replace('.fbx', '.json'), 'w') as f:
            json.dump(asset_data, f, indent=2)
        
        return {
            "success": True,
            "asset_path": output_path,
            "asset_data": asset_data,
            "ready_for_unreal": True
        }
    
    async def _create_3d_specifications(
        self,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create detailed 3D model specifications"""
        
        return {
            "geometry": {
                "poly_count_target": analysis.get("estimated_poly_count", "medium"),
                "lod_levels": 3,
                "subdivision_level": 2
            },
            "materials": {
                "count": len(analysis.get("materials_needed", ["Base"])),
                "types": analysis.get("materials_needed", ["Base Material"]),
                "pbr": True,
                "texture_resolution": "2048x2048"
            },
            "rigging": {
                "required": "character" in analysis.get("asset_type", ""),
                "bone_count": 50 if "character" in analysis.get("asset_type", "") else 0,
                "ik_chains": ["arms", "legs"] if "character" in analysis.get("asset_type", "") else []
            },
            "physics": {
                "collision_mesh": True,
                "physics_asset": "character" in analysis.get("asset_type", ""),
                "mass_kg": 80 if "character" in analysis.get("asset_type", "") else 10
            },
            "animations": analysis.get("animations_needed", [])
        }
    
    async def _generate_2d_sprite(
        self,
        image_path: str,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate 2D sprite from image"""
        
        # Process image for sprite use
        output_path = f"assets/generated_sprites/{analysis.get('suggested_name', 'Sprite')}_{int(time.time())}.png"
        os.makedirs("assets/generated_sprites", exist_ok=True)
        
        # Copy and process image
        img = Image.open(image_path)
        
        # Remove background if needed
        # Apply style transformations
        # Generate sprite sheet if multiple poses
        
        img.save(output_path)
        
        return {
            "success": True,
            "asset_path": output_path,
            "asset_type": "2D_sprite",
            "ready_for_unreal": True
        }
    
    async def _generate_procedural(
        self,
        image_path: str,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate procedural generation code"""
        
        # Generate code that procedurally creates the asset
        return {
            "success": True,
            "asset_type": "procedural",
            "code_generated": True
        }
    
    async def _generate_code_based(
        self,
        image_path: str,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate code-based asset (like UI elements)"""
        
        return {
            "success": True,
            "asset_type": "code_based"
        }
    
    async def generate_blueprint_from_image(
        self,
        image_path: str,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate Unreal Blueprint logic from image/diagram
        Useful for flowcharts and logic diagrams
        """
        
        prompt = f"""Based on this image analysis, generate Unreal Engine Blueprint logic:

ANALYSIS:
{json.dumps(analysis, indent=2)}

Generate Blueprint node structure in JSON format:
{{
    "blueprint_class": "Actor|Component|Widget|etc",
    "nodes": [
        {{
            "type": "BeginPlay|Tick|CustomEvent",
            "connections": ["node_id"],
            "parameters": {{}}
        }}
    ],
    "variables": [
        {{
            "name": "variable_name",
            "type": "float|int|bool|etc",
            "default": value
        }}
    ],
    "functions": []
}}"""

        try:
            async with self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {self.openai_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4-turbo-preview",
                    "messages": [
                        {"role": "system", "content": "You are an Unreal Engine Blueprint expert."},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "response_format": {"type": "json_object"}
                }
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    blueprint = json.loads(result["choices"][0]["message"]["content"])
                    
                    return {
                        "success": True,
                        "blueprint": blueprint,
                        "can_auto_create": True
                    }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
        
        return {"success": False}

class ImageToGameConverter:
    """
    Complete system to convert images into playable game elements
    """
    
    def __init__(self, openai_key: str, api_url: str):
        self.vision_system = AIVisionSystem(openai_key)
        self.openai_key = openai_key
        self.api_url = api_url
        self.session = None
        
    async def setup_session(self):
        """Initialize session"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        await self.vision_system.setup_session()
    
    async def close_session(self):
        """Close session"""
        if self.session:
            await self.session.close()
        await self.vision_system.close_session()
    
    async def convert_to_game_asset(
        self,
        image_path: str,
        user_description: str,
        auto_integrate: bool = True
    ) -> Dict[str, Any]:
        """
        Complete pipeline: Image → Analysis → 3D Asset → Integration
        """
        
        await self.setup_session()
        
        results = {
            "steps": [],
            "assets_created": [],
            "code_generated": [],
            "ready_for_game": False
        }
        
        # Step 1: Analyze image
        results["steps"].append("Analyzing image with AI Vision...")
        analysis = await self.vision_system.analyze_image(image_path, user_description)
        
        if not analysis.get("success"):
            return {"success": False, "error": "Image analysis failed"}
        
        results["analysis"] = analysis
        results["steps"].append(f"✓ Identified: {analysis['parsed'].get('asset_type', 'asset')}")
        
        # Step 2: Generate 3D asset
        results["steps"].append("Generating 3D asset...")
        asset = await self.vision_system.generate_3d_from_image(
            image_path,
            analysis["parsed"]
        )
        
        if asset.get("success"):
            results["assets_created"].append(asset)
            results["steps"].append(f"✓ Created: {asset.get('asset_path')}")
        
        # Step 3: Generate supporting code
        results["steps"].append("Generating C++ code...")
        code = await self._generate_supporting_code(analysis["parsed"])
        
        if code.get("success"):
            results["code_generated"].append(code)
            results["steps"].append(f"✓ Generated: {code.get('class_name')}")
        
        # Step 4: Generate Blueprint
        results["steps"].append("Creating Blueprint logic...")
        blueprint = await self.vision_system.generate_blueprint_from_image(
            image_path,
            analysis["parsed"]
        )
        
        if blueprint.get("success"):
            results["blueprint"] = blueprint
            results["steps"].append("✓ Blueprint created")
        
        # Step 5: Create materials
        results["steps"].append("Generating materials...")
        materials = await self._generate_materials(analysis["parsed"])
        results["materials"] = materials
        results["steps"].append(f"✓ Created {len(materials)} materials")
        
        # Step 6: Integration package
        if auto_integrate:
            results["steps"].append("Creating integration package...")
            package = self._create_integration_package(results)
            results["integration_package"] = package
            results["ready_for_game"] = True
            results["steps"].append("✓ Ready for Unreal Engine!")
        
        return results
    
    async def _generate_supporting_code(
        self,
        analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate C++ code for the asset"""
        
        asset_type = analysis.get("asset_type", "prop")
        asset_name = analysis.get("suggested_name", "Asset")
        
        # Determine base class
        base_class = {
            "character": "ACharacter",
            "vehicle": "APawn",
            "weapon": "AActor",
            "prop": "AActor",
            "building": "AActor"
        }.get(asset_type, "AActor")
        
        prompt = f"""Generate Unreal Engine C++ code for this asset:

TYPE: {asset_type}
NAME: {asset_name}
BASE CLASS: {base_class}
FEATURES: {', '.join(analysis.get('key_features', []))}
COMPONENTS: {', '.join(analysis.get('unreal_components', []))}

Generate complete header (.h) and source (.cpp) files.
Include:
- Proper UCLASS/UPROPERTY/UFUNCTION macros
- Component initialization
- Blueprint-callable functions
- Basic gameplay logic based on features
"""

        try:
            async with self.session.post(
                f"{self.api_url}/code/generate",
                json={
                    "prompt": prompt,
                    "engine_type": "unreal",
                    "project_id": 1,
                    "ai_model": "gpt-4",
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "include_comments": True,
                    "optimize_code": True
                }
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    # Save code
                    code_path = f"assets/generated_code/{asset_name}_{int(time.time())}.cpp"
                    os.makedirs("assets/generated_code", exist_ok=True)
                    
                    with open(code_path, 'w') as f:
                        f.write(result.get("generated_code", ""))
                    
                    return {
                        "success": True,
                        "class_name": f"A{asset_name}",
                        "code_path": code_path,
                        "base_class": base_class
                    }
        except Exception as e:
            print(f"Code generation error: {e}")
        
        return {"success": False}
    
    async def _generate_materials(
        self,
        analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Generate material definitions"""
        
        materials_needed = analysis.get("materials_needed", ["Base Material"])
        colors = analysis.get("colors", ["gray"])
        
        materials = []
        
        for i, material_type in enumerate(materials_needed):
            material = {
                "name": f"M_{analysis.get('suggested_name', 'Asset')}_{material_type}",
                "type": "PBR",
                "base_color": colors[i % len(colors)],
                "roughness": 0.5,
                "metallic": 0.0 if "wood" in material_type.lower() else 0.3,
                "settings": {
                    "two_sided": False,
                    "cast_shadow": True,
                    "translucent": False
                }
            }
            materials.append(material)
        
        return materials
    
    def _create_integration_package(
        self,
        results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create complete integration package"""
        
        package = {
            "package_name": "ImageGeneratedAsset",
            "assets": [asset.get("asset_path") for asset in results.get("assets_created", [])],
            "code_files": [code.get("code_path") for code in results.get("code_generated", [])],
            "materials": results.get("materials", []),
            "blueprint": results.get("blueprint"),
            "import_instructions": self._generate_import_instructions(results),
            "test_level": self._generate_test_level_config(results)
        }
        
        # Save package info
        package_path = f"assets/integration_packages/package_{int(time.time())}.json"
        os.makedirs("assets/integration_packages", exist_ok=True)
        
        with open(package_path, 'w') as f:
            json.dump(package, f, indent=2)
        
        package["package_path"] = package_path
        return package
    
    def _generate_import_instructions(
        self,
        results: Dict[str, Any]
    ) -> str:
        """Generate step-by-step import instructions"""
        
        return f"""UNREAL ENGINE IMPORT INSTRUCTIONS:

1. IMPORT ASSETS:
   - Open Unreal Engine project
   - Drag {len(results.get('assets_created', []))} asset(s) into Content Browser
   - Assets will auto-import with settings

2. IMPORT CODE:
   - Copy C++ files to: YourProject/Source/YourProject/
   - Regenerate project files
   - Compile in Visual Studio

3. SETUP MATERIALS:
   - Materials automatically applied
   - Verify in Material Editor

4. TEST IN LEVEL:
   - Create new level or open existing
   - Place asset from Content Browser
   - Hit Play to test

5. CUSTOMIZE:
   - Use Visual Editor to tweak properties
   - Modify Blueprint logic as needed
   - Adjust materials and textures

DONE! Your image is now a game asset!
"""
    
    def _generate_test_level_config(
        self,
        results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate test level configuration"""
        
        return {
            "level_name": "TestLevel_Generated",
            "lighting": "Day",
            "skybox": "DefaultSky",
            "ground": "Plane",
            "camera_position": [0, 0, 300],
            "asset_placement": {
                "position": [0, 0, 0],
                "rotation": [0, 0, 0],
                "scale": [1, 1, 1]
            },
            "test_scenarios": [
                "Place asset in level",
                "Test collision",
                "Verify materials",
                "Test any custom behavior"
            ]
        }
